@techreport{tefft2014prevalence,
  author       = {Tefft, Brian C.},
  title        = {Prevalence of Motor Vehicle Crashes Involving Drowsy Drivers, United States, 2009--2013},
  institution  = {AAA Foundation for Traffic Safety},
  address      = {607 14th Street, NW, Suite 201, Washington, DC 20005},
  month        = {November},
  year         = {2014},
  url          = {https://newsroom.aaa.com/wp-content/uploads/2019/06/AAAFoundation-DrowsyDriving-Nov2014.pdf}
}
@article{AHMAD2023418,
title = {Heterogeneous ensemble learning for enhanced crash forecasts – A frequentist and machine learning based stacking framework},
journal = {Journal of Safety Research},
volume = {84},
pages = {418-434},
year = {2023},
issn = {0022-4375},
doi = {https://doi.org/10.1016/j.jsr.2022.12.005},
url = {https://www.sciencedirect.com/science/article/pii/S002243752200202X},
author = {Numan Ahmad and Behram Wali and Asad J. Khattak},
keywords = {Crash frequency, Crash prediction, Count data models, Machine learning, Base-learners, Meta-learner, Stacking},
abstract = {Introduction: This study aims to increase the prediction accuracy of crash frequency on roadway segments that can forecast future safety on roadway facilities. A variety of statistical and machine learning (ML) methods are used to model crash frequency with ML methods generally having a higher prediction accuracy. Recently, heterogeneous ensemble methods (HEM), including “stacking,” have emerged as more accurate and robust intelligent techniques providing more reliable and accurate predictions. Methods: This study applies “Stacking” to model crash frequency on five-lane undivided (5 T) segments of urban and suburban arterials. The prediction performance of “Stacking” is compared with parametric statistical models (Poisson and negative binomial) and three state-of-the-art ML techniques (Decision tree, random forest, and gradient boosting), each of which is termed as the base-learner. By employing an optimal weight scheme to combine individual base-learners through stacking, the problem of biased predictions in individual base-learners due to differences in specifications and prediction accuracies is avoided. Data including crash, traffic, and roadway inventory were collected and integrated from 2013 to 2017. The data are split into training (2013–2015), validation (2016), and testing (2017) datasets. After training five individual base-learners using training data, prediction outcomes are obtained for the five base-learners using validation data that are then used to train a meta-learner. Results: Results of statistical models reveal that crashes increase with the density (number per mile) of commercial driveways whereas decrease with average offset distance to fixed objects. Individual ML methods show similar results – in terms of variable importance. A comparison of out-of-sample predictions of various models or methods confirms the superiority of “Stacking” over the alternative methods considered. Conclusions and practical applications: From a practical standpoint, “stacking” can enhance prediction accuracy (compared to only one base-learner with a particular specification). When applied systemically, stacking can help identify more appropriate countermeasures.}
}
@article{Jebraeily2024DriverDD,
  title={Driver Drowsiness Detection Based on Convolutional Neural Network Architecture Optimization Using Genetic Algorithm},
  author={Yashar Jebraeily and Yousef Sharafi and Mohammad Teshnehlab},
  journal={IEEE Access},
  year={2024},
  volume={12},
  pages={45709-45726},
  url={https://api.semanticscholar.org/CorpusID:268761612}
}
@techreport{maineDOT2021sleepdeprivation,
  author       = {{Maine Department of Transportation}},
  title        = {Sleep Deprived? How Does this Compare to Drinking too Much Alcohol?},
  institution  = {Maine Department of Transportation},
  month        = {November},
  year         = {2021},
  url          = {https://www.maine.gov/mdot/challengeme/topics/docs/2021/1121SleepDeprivation.pdf}
}
@ARTICLE{8269243,
  author={Chang, Yakun and Jung, Cheolkon and Ke, Peng and Song, Hyoseob and Hwang, Jungmee},
  journal={IEEE Access}, 
  title={Automatic Contrast-Limited Adaptive Histogram Equalization With Dual Gamma Correction}, 
  year={2018},
  volume={6},
  number={},
  pages={11782-11792},
  keywords={Histograms;Dynamic range;Image enhancement;Interpolation;Visualization;Image segmentation;Transfer functions;CLAHE;luminance enhancement;contrast enhancement;gamma correction;dark image;over-enhancement},
  doi={10.1109/ACCESS.2018.2797872}
}
@article{Dzeroski2004,
  author       = {DZeroski, Saso and Zenko, Bernard},
  title        = {Is Combining Classifiers with Stacking Better than Selecting the Best One?},
  journal      = {Machine Learning},
  year         = {2004},
  month        = mar,
  volume       = {54},
  number       = {3},
  pages        = {255--273},
  doi          = {10.1023/B:MACH.0000015881.36452.6e},
  url          = {https://doi.org/10.1023/B:MACH.0000015881.36452.6e},
  issn         = {1573-0565},
  abstract     = {We empirically evaluate several state-of-the-art methods for constructing ensembles of heterogeneous classifiers with stacking and show that they perform (at best) comparably to selecting the best classifier from the ensemble by cross validation. Among state-of-the-art stacking methods, stacking with probability distributions and multi-response linear regression performs best. We propose two extensions of this method, one using an extended set of meta-level features and the other using multi-response model trees to learn at the meta-level. We show that the latter extension performs better than existing stacking approaches and better than selecting the best classifier by cross validation.}
}

